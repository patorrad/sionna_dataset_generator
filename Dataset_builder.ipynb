{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 14:35:19.079942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742592919.091171  913088 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742592919.094507  913088 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 14:35:19.107008: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "jit_find_library(): Unable to load \"/usr/lib/x86_64-linux-gnu/libLLVM.so:\": /usr/lib/x86_64-linux-gnu/libLLVM.so:: cannot open shared object file: No such file or directory!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Found 1 GPUs\n",
      "Found GPU: /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742592920.927129  913088 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Jason's implementation of directional algo\n",
    "from algorithim import Params, Algorithm, Capon\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import os\n",
    "os.environ['DRJIT_LIBLLVM_PATH'] = '/usr/lib/x86_64-linux-gnu/libLLVM.so:'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import os # Configure which GPU\n",
    "\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0 # Use \"\" to use the CPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "    print(f\"Using GPU {gpu_num}\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"Found {len(gpus)} GPUs\")\n",
    "if gpus:\n",
    "    print(f\"Found GPU: {gpus[0].name}\")\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Colab does currently not support the latest version of ipython.\n",
    "# Thus, the preview does not work in Colab. However, whenever possible we\n",
    "# strongly recommend to use the scene preview mode.\n",
    "try: # detect if the notebook runs in Colab\n",
    "    import google.colab\n",
    "    no_preview = True # deactivate preview\n",
    "except:\n",
    "    if os.getenv(\"SIONNA_NO_PREVIEW\"):\n",
    "        no_preview = True\n",
    "    else:\n",
    "        no_preview = False\n",
    "\n",
    "resolution = [480,320] # increase for higher quality of renderings\n",
    "\n",
    "# Define magic cell command to skip a cell if needed\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    if eval(line):\n",
    "        return\n",
    "    get_ipython().run_cell(cell)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "sionna.config.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Import Sionna RT components\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera, AntennaArray, Antenna\n",
    "\n",
    "# For link-level simulations\n",
    "from sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\n",
    "from sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\n",
    "from sionna.utils import compute_ber, ebnodb2no, PlotBER\n",
    "from sionna.ofdm import KBestDetector, LinearDetector\n",
    "from sionna.mimo import StreamManagement\n",
    "from sionna.ofdm import ResourceGrid\n",
    "\n",
    "def calculate_heading_rad(start, end):\n",
    "    # Calculate the difference vector\n",
    "    diff = np.array(end) - np.array(start)\n",
    "    \n",
    "    # Calculate the heading angle in radians\n",
    "    heading = np.arctan2(diff[1], diff[0])\n",
    "    \n",
    "    return heading\n",
    "\n",
    "def get_rss_from_csi(csi):\n",
    "  # Compute CSI power (power per subcarrier)\n",
    "  csi_power = tf.abs(csi)**2\n",
    "\n",
    "  # Compute RSS per receiver-transmitter pair (sum over subcarriers)\n",
    "  rss_per_rx_tx = tf.reduce_sum(csi_power, axis=-1)  # Sum over subcarriers\n",
    "\n",
    "  # Convert RSS from linear scale (e.g., Watts) to dBm\n",
    "  rss_per_rx_tx_dBm = 10 * tf.math.log(rss_per_rx_tx / 1e-3) / tf.math.log(10.0)\n",
    "\n",
    "  return rss_per_rx_tx_dBm\n",
    "\n",
    "def dbm_to_watts(dbm):\n",
    "    return 10. ** ((dbm-30)/10)\n",
    "\n",
    "def watts_to_dbm(watts):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return 10 * np.log10(watts + epsilon) + 30\n",
    "\n",
    "# # Multiple Antennas like ASUS Router\n",
    "def get_antenna_positions(spacing):\n",
    "    return np.array([[0.0, spacing / 2 + spacing , 0.0],\n",
    "                     [0.0, spacing / 2, 0.0],\n",
    "                     [0.0, -spacing / 2, 0.0],\n",
    "                     [0.0, -spacing / 2 - spacing, 0.0]])\n",
    "\n",
    "def flip_trajectory(data):\n",
    "    # Vector from origin to the first and last points of each trajectory\n",
    "    first_points = data[:, 0, :]  # Shape (1000, 3)\n",
    "    last_points = data[:, -1, :]  # Shape (1000, 3)\n",
    "\n",
    "    # Compute the dot product of the first and last points with respect to the origin\n",
    "    dot_products = np.sum(first_points * last_points, axis=1)\n",
    "\n",
    "    # Identify trajectories heading away from the origin (dot product > 0)\n",
    "    away_from_origin = dot_products < 0\n",
    "\n",
    "    # Flip the trajectories that are not heading away from the origin\n",
    "    data[~away_from_origin] = data[~away_from_origin, ::-1, :]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List for dataset\n",
    "angles = []\n",
    "angle_profile_values = []\n",
    "rssi = []\n",
    "rssi_normalized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty(shape=(0, 20))\n",
    "total_traj = 20\n",
    "\n",
    "for traj in range(total_traj):\n",
    "    SCENE_NAME = \"canyon\"\n",
    "    IMAGE_FOLDER = f\"images/{SCENE_NAME}\"\n",
    "\n",
    "    # Load integrated scene\n",
    "    scene = load_scene(f\"models/{SCENE_NAME}.xml\") # Try also sionna.rt.scene.etoile\n",
    "\n",
    "    # Configure antenna array for all transmitters\n",
    "    scene.tx_array = PlanarArray(num_rows=1,\n",
    "                                num_cols=1,\n",
    "                                vertical_spacing=0.5,\n",
    "                                horizontal_spacing=0.5,\n",
    "                                pattern=\"iso\",\n",
    "                                polarization=\"V\")\n",
    "\n",
    "    antenna_positions = get_antenna_positions(0.03)\n",
    "    antenna_array_angle = -175 # Default\n",
    "\n",
    "    RelativeAntennas = AntennaArray(antenna=Antenna(\"dipole\", \"V\"), \n",
    "                                positions=tf.Variable(antenna_positions.tolist()))\n",
    "\n",
    "    # scene.tx_array = RelativeAntennas \n",
    "    scene.rx_array = RelativeAntennas\n",
    "\n",
    "    # Create transmitter\n",
    "    tx = Transmitter(name=\"tx\",\n",
    "                    position=[0., -10., 0.],\n",
    "                    orientation=[np.radians(0),0,0])\n",
    "\n",
    "    # Add transmitter instance to scene\n",
    "    scene.add(tx)\n",
    "\n",
    "    trajectories = np.load('trajectories_2.npy')\n",
    "    trajectories = flip_trajectory(trajectories)\n",
    "    trajectory_index = traj\n",
    "    num_steps = trajectories.shape[1]\n",
    "    trajectory_steps =  np.arange(num_steps - 1)\n",
    "\n",
    "    start_color = np.array([1, 0, 0])  # Red\n",
    "    end_color = np.array([0, 0, 1]) \n",
    "    colors = [start_color + (end_color - start_color) * i / (num_steps - 1) for i in range(num_steps)]\n",
    "\n",
    "    # Calculate headings for the trajectory\n",
    "    calculated_headings = []\n",
    "    for i in trajectory_steps: #range(0, len(trajectories[0]) - 1):\n",
    "        heading = calculate_heading_rad(trajectories[trajectory_index,i,:2], trajectories[trajectory_index,i + 1,:2])\n",
    "        calculated_headings.append(heading)\n",
    "\n",
    "    rxs = []\n",
    "    for i, position in enumerate(trajectories[trajectory_index, np.arange(num_steps) ,:]):\n",
    "        if i == (trajectories[0].shape[0] - 1):\n",
    "            heading = calculated_headings[-1]\n",
    "        else:\n",
    "            heading = calculated_headings[i]\n",
    "        rxs.append(Receiver(name=f\"rx{i}\",\n",
    "                position=position,\n",
    "                orientation=[heading,0,0]))   \n",
    "        scene.add(rxs[i])\n",
    "\n",
    "    antenna_array_angle = np.radians(180) # heading\n",
    "\n",
    "    scene.frequency = 2.14e9 #5.745 # in Hz; implicitly updates RadioMaterials\n",
    "\n",
    "    scene.synthetic_array = False # If set to False, ray tracing will be done per antenna element (slower for large arrays)\n",
    "\n",
    "    # Compute propagation paths\n",
    "    paths = scene.compute_paths(max_depth=5,\n",
    "                                num_samples=1e6,  # Number of rays shot into directions defined\n",
    "                                                # by a Fibonacci sphere , too few rays can\n",
    "                                                # lead to missing paths\n",
    "                                los=True,  # Include Line-of-Sight paths\n",
    "                                reflection=True,  # Include reflection paths\n",
    "                                diffraction=True,  # Include diffraction paths\n",
    "                                scattering=True,  # Include scattering paths\n",
    "                                )\n",
    "\n",
    "    paths.normalize_delays = False\n",
    "\n",
    "    # Determine subcarrier frequencies\n",
    "    rg = ResourceGrid(num_ofdm_symbols=1,\n",
    "                    fft_size=52,\n",
    "                    dc_null = True,\n",
    "                    cyclic_prefix_length=20,\n",
    "                    #   pilot_pattern = \"kronecker\",\n",
    "                    #   pilot_ofdm_symbol_indices = [2, 8],\n",
    "                    subcarrier_spacing=5e6) #30e3)\n",
    "\n",
    "    frequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n",
    "\n",
    "    # get rss\n",
    "    a, tau = paths.cir()\n",
    "\n",
    "    csi = cir_to_ofdm_channel(frequencies, a, tau, normalize=False)  # Non-normalized includes path-loss\n",
    "   \n",
    "    csi_reshaped = []\n",
    "    for i in range(len(rxs)):\n",
    "        csi_reshaped.append(np.array(csi[:,i,:,:,:,:,:]).reshape(4, 52))\n",
    "\n",
    "    #Output: h_f ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, fft_size], tf.complex) – Channel frequency responses at frequencies\n",
    "    block_rss = get_rss_from_csi(csi).numpy()[0, :, 0, 0, 0, 0]\n",
    "    block_rss[np.isneginf(block_rss)] = -90\n",
    "    rssi.append(block_rss[:-1])\n",
    "    # Define range\n",
    "    min_rss = -90\n",
    "    max_rss = 0\n",
    "\n",
    "    # Normalize values to 0-1\n",
    "    normalized = (block_rss - min_rss) / (max_rss - min_rss)\n",
    "    rssi_normalized.append(normalized[:-1])\n",
    "\n",
    "    # Define three colors\n",
    "    color_black = np.array([0, 0, 0])\n",
    "    color_red = np.array([1, 0, 0])\n",
    "    color_blue = np.array([0, 0, 1])\n",
    "    colors = []\n",
    "    for value in normalized:\n",
    "        if value <= 0.5:\n",
    "            # Scale between black and gray\n",
    "            color = color_black + (color_red - color_black) * (value / 0.5)\n",
    "        else:\n",
    "            # Scale between gray and white\n",
    "            color = color_red + (color_blue - color_red) * ((value - 0.5) / 0.5)\n",
    "        colors.append(color)\n",
    "\n",
    "    # Map normalized values to colors\n",
    "    # 0-1 range is split into 3 intervals: [0, 1/3), [1/3, 2/3), [2/3, 1]\n",
    "    # color_indices = np.digitize(normalized, bins=[1/3, 2/3], right=False)\n",
    "    # mapped_colors = [colors[idx] for idx in color_indices]\n",
    "\n",
    "    for i, rx in enumerate(rxs):\n",
    "        rx.color = colors[i]\n",
    "\n",
    "\n",
    "    # Implementing Capon Algorithim\n",
    "    params = Params(antenna_positions[:, :2])\n",
    "\n",
    "    angle_tmp = []\n",
    "    angle_profile_values_tmp = []\n",
    "    for i in range(0, len(rxs) - 1):\n",
    "        \n",
    "        csi_tmp = tf.reshape(csi[:,i,:,:,:,:,:], [4, 52]) #  tf.reshape(csi[:,i,:,:,:,:,:], [1, -1])\n",
    "\n",
    "        AOA, theta_samples, profile_norm = Capon(params, 155, 80, csi_tmp).evaluate()\n",
    "\n",
    "        # This for when going towards transmitter\n",
    "        profile_norm = np.roll(profile_norm, 180)\n",
    "        # Capture three top peaks from bottom of profile (90-270 degrees)\n",
    "        evaluation = np.array([profile_norm[90:270]])\n",
    "        evaluation = evaluation.flatten() \n",
    "        peaks, _ = find_peaks(evaluation)\n",
    "        peak_values = evaluation[peaks]\n",
    "        angle_profile_values_tmp.append(np.pad(peak_values, (0, max(0, 3 - peak_values.shape[0])), mode='constant'))\n",
    "        angle_tmp.append(np.pad(theta_samples[90:270][peaks], (0, max(0, 3 - theta_samples[90:270][peaks].shape[0])), mode='constant'))\n",
    "        AOA = np.array([AOA])\n",
    "\n",
    "\n",
    "    angles.append(angle_tmp)\n",
    "    angle_profile_values.append(angle_profile_values_tmp)\n",
    "\n",
    "    for i in range(0, len(rssi[0])):\n",
    "        data = np.append(data, [rssi_normalized[0][i], angles[0][i][0], angles[0][i][1], angles[0][i][2], angle_profile_values[0][i][0], angle_profile_values[0][i][1], angle_profile_values[0][i][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 19, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(rssi_normalized)\n",
    "# print(angles)\n",
    "# print(angle_profile_values)\n",
    "\n",
    "# data = np.empty(shape=(0, 20))\n",
    "# for i in range(0, len(rssi[0])):\n",
    "#     data = np.append(data, [rssi_normalized[0][i], angles[0][i][0], angles[0][i][1], angles[0][i][2], angle_profile_values[0][i][0], angle_profile_values[0][i][1], angle_profile_values[0][i][2]])\n",
    "\n",
    "# # angles = []\n",
    "# # angle_profile_values = []\n",
    "# # rssi = []\n",
    "# # rssi_normalized = []\n",
    "\n",
    "# print(data.shape[0]/7)\n",
    "# print(rssi_normalized[0].shape)\n",
    "print(data.reshape(total_traj, -1, 7).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpatorrad\u001b[0m (\u001b[33msensors_lab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paolo/Documents/sionna/Sionna_dataset_generator/wandb/run-20250321_143434-hinhc0qc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sensors_lab/NASA_DCG/runs/hinhc0qc' target=\"_blank\">pleasant-rain-1</a></strong> to <a href='https://wandb.ai/sensors_lab/NASA_DCG' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sensors_lab/NASA_DCG' target=\"_blank\">https://wandb.ai/sensors_lab/NASA_DCG</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sensors_lab/NASA_DCG/runs/hinhc0qc' target=\"_blank\">https://wandb.ai/sensors_lab/NASA_DCG/runs/hinhc0qc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sensors_lab/NASA_DCG/runs/hinhc0qc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x76a8d4555ab0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# wandb.login(key=\"ce83088be33d33e8cf0be4f78a8c7e9116cd4072\") \n",
    "num_epochs = 10\n",
    "\n",
    "wandb.init(\n",
    "    project=\"NASA_DCG\",  # change this to your project name\n",
    "    config={\n",
    "        \"input_size\": 7,\n",
    "        \"seq_len\": 18,\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_layers\": 1,\n",
    "        \"batch_size\": 5,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"lr\": 1e-3\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Assuming data shape is (20, 19, 7)\n",
    "data = data.reshape(20, 19, 7)  # each \"trajectory\" is a sample\n",
    "\n",
    "# Define a custom dataset\n",
    "class TrajectoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data = data_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]  # shape (19, 7)\n",
    "        input_seq = seq[:-1]         # (18, 7)\n",
    "        target_value = seq[-1, 0]    # scalar: next-step value of first feature\n",
    "        return input_seq, target_value\n",
    "\n",
    "\n",
    "# Wrap your tensor in the dataset\n",
    "dataset = TrajectoryDataset(torch.tensor(data, dtype=torch.float32))\n",
    "\n",
    "# Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size=7, hidden_size=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # output single value per sequence\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)     # hn: (num_layers, batch, hidden)\n",
    "        last_hidden = hn[-1]             # (batch, hidden_size)\n",
    "        output = self.fc(last_hidden)    # (batch, 1)\n",
    "        return output.squeeze(1)         # return (batch,) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMRegressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for input_seq, target_val in train_loader:\n",
    "        output = model(input_seq)\n",
    "        loss = criterion(output, target_val)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Log training loss\n",
    "    wandb.log({\"train_loss\": loss.item(), \"epoch\": epoch})\n",
    "\n",
    "    # Optional test loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        for input_seq, target_val in test_loader:\n",
    "            test_output = model(input_seq)\n",
    "            test_loss = criterion(test_output, target_val)\n",
    "            test_losses.append(test_loss.item())\n",
    "        avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "    wandb.log({\"test_loss\": avg_test_loss, \"epoch\": epoch})\n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size, 19)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Move predictions and real values back to CPU for visualization\u001b[39;00m\n\u001b[1;32m     14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mLSTMRegressor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# hn: (num_layers, batch, hidden)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     last_hidden \u001b[38;5;241m=\u001b[39m hn[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]             \u001b[38;5;66;03m# (batch, hidden_size)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(last_hidden)    \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get a test batch\n",
    "test_x, test_y = next(iter(test_loader))  # Get one batch from the DataLoader\n",
    "test_x, test_y = test_x.to('cpu'), test_y.to('cpu')  # Move to GPU if available\n",
    "\n",
    "# Predict using the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_x)  # Shape: (batch_size, 19)\n",
    "\n",
    "# Move predictions and real values back to CPU for visualization\n",
    "predictions = predictions.cpu().numpy()\n",
    "test_y = test_y.cpu().numpy()\n",
    "\n",
    "# Select a sample from the batch to visualize\n",
    "sample_idx = 0  # Choose the first trajectory in the batch\n",
    "time_steps = np.arange(19)  # Time step indices\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time_steps, test_y[sample_idx], label=\"Ground Truth\", marker=\"o\")\n",
    "plt.plot(time_steps, predictions[sample_idx], label=\"Predicted\", marker=\"x\")\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Target Value (y)\")\n",
    "plt.title(f\"Trajectory Prediction Comparison (Sample {sample_idx})\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Compute MSE (Lower is better)\n",
    "mse = mean_squared_error(test_y.flatten(), predictions.flatten())\n",
    "mae = mean_absolute_error(test_y.flatten(), predictions.flatten())\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
