{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danishubin/sionna_dataset_generator.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEzM2Qs82K0I",
        "outputId": "e3784924-fa08-4091-fa8e-97b838a0225b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sionna_dataset_generator'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 66 (delta 7), reused 7 (delta 6), pack-reused 54 (from 1)\u001b[K\n",
            "Receiving objects: 100% (66/66), 30.74 MiB | 8.87 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh\n",
        "!pip install rtree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmKBZ9PBYgUJ",
        "outputId": "3648a75d-86b4-4bcf-9ced-d84912216b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.6.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from trimesh) (1.26.4)\n",
            "Downloading trimesh-4.6.4-py3-none-any.whl (708 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.6/708.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.6.4\n",
            "Collecting rtree\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rtree\n",
            "Successfully installed rtree-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sionna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLnpiuiWYlNX",
        "outputId": "054cc26f-5236-4abb-bf42-267b6da25b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sionna\n",
            "  Downloading sionna-0.19.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tensorflow<2.16.0,>=2.13.0 (from sionna)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sionna) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.11/dist-packages (from sionna) (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from sionna) (1.13.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from sionna) (6.5.2)\n",
            "Collecting mitsuba<3.6.0,>=3.2.0 (from sionna)\n",
            "  Downloading mitsuba-3.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pythreejs>=2.4.2 (from sionna)\n",
            "  Downloading pythreejs-2.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ipydatawidgets==4.3.2 (from sionna)\n",
            "  Downloading ipydatawidgets-4.3.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting jupyterlab-widgets==3.0.5 (from sionna)\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipydatawidgets==4.3.2->sionna) (0.2.1)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->sionna) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->sionna) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->sionna)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting ipywidgets>=8.0.4 (from sionna)\n",
            "  Downloading ipywidgets-8.1.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading ipywidgets-8.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.4->sionna) (6.17.1)\n",
            "  Downloading ipywidgets-8.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is still looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->sionna) (2.8.2)\n",
            "Collecting drjit==0.4.6 (from mitsuba<3.6.0,>=3.2.0->sionna)\n",
            "  Downloading drjit-0.4.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16.0,>=2.13.0->sionna) (1.70.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16.0,>=2.13.0->sionna)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.13.0->sionna) (0.45.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->sionna) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.13.0->sionna) (3.2.2)\n",
            "Downloading sionna-0.19.2-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipydatawidgets-4.3.2-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.3/384.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mitsuba-3.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (40.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading drjit-0.4.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pythreejs-2.4.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, widgetsnbextension, tensorflow-estimator, ml-dtypes, keras, jupyterlab-widgets, jedi, drjit, mitsuba, ipywidgets, tensorboard, ipydatawidgets, tensorflow, pythreejs, sionna\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: jupyterlab-widgets\n",
            "    Found existing installation: jupyterlab_widgets 3.0.13\n",
            "    Uninstalling jupyterlab_widgets-3.0.13:\n",
            "      Successfully uninstalled jupyterlab_widgets-3.0.13\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed drjit-0.4.6 ipydatawidgets-4.3.2 ipywidgets-8.0.5 jedi-0.19.2 jupyterlab-widgets-3.0.5 keras-2.15.0 mitsuba-3.5.2 ml-dtypes-0.3.2 pythreejs-2.4.2 sionna-0.19.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 widgetsnbextension-4.0.13 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaFsCdP7YuCV",
        "outputId": "04a09a63-488e-4eee-c8b7-4c56f9567444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.1\n",
            "Uninstalling tensorflow-2.15.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow-2.15.1.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.15.1\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow)\n",
            "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sionna 0.19.2 requires tensorflow<2.16.0,>=2.13.0, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.9.0 ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "TZ1IWAo6ZjBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sionna"
      ],
      "metadata": {
        "id": "P8ZoktsJY0eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Additional Trajectories"
      ],
      "metadata": {
        "id": "t8I-Pa07YDB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import trimesh\n",
        "\n",
        "from math import tan, sin, cos, sqrt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dt = 1.0\n",
        "wheelbase = 0.5\n",
        "cmds = [np.array([.8, np.random.choice([1, -1]) * .01])] * 20\n",
        "step = 1\n",
        "\n",
        "def move(x, dt, u, wheelbase):\n",
        "    hdg = x[2]\n",
        "    vel = u[0]\n",
        "    steering_angle = u[1]\n",
        "    dist = vel * dt\n",
        "    if abs(steering_angle) > 0.001: # is robot turning?\n",
        "        beta = (dist / wheelbase) * tan(steering_angle)\n",
        "        r = wheelbase / tan(steering_angle) # radius\n",
        "        sinh, sinhb = sin(hdg), sin(hdg + beta)\n",
        "        cosh, coshb = cos(hdg), cos(hdg + beta)\n",
        "        return x + np.array([-r*sinh + r*sinhb,\n",
        "                              r*cosh - r*coshb, beta]), np.array([-vel*sinh + vel*sinhb, vel*cosh - vel*coshb]), hdg\n",
        "    else: # moving in straight line\n",
        "        return x + np.array([dist*cos(hdg), dist*sin(hdg), 0]), np.array([vel*cos(hdg), vel*sin(hdg)]), hdg\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    trajectories = np.empty((0,20,3))\n",
        "\n",
        "    for i in range(20):\n",
        "        cmds = [np.array([np.random.choice([1, -1]) * np.random.uniform(.2, .8), np.random.choice([1, -1]) * .01])] * 20\n",
        "        # Generate trajectories\n",
        "        track = []\n",
        "        velocity = []\n",
        "        heading = []\n",
        "        sim_pos = np.array([np.random.uniform(10, 50), np.random.uniform(-5, 2), np.random.uniform(0, np.pi / 2)])\n",
        "        # sim_pos = np.array([30, 5, 0])\n",
        "        for i, u in enumerate(cmds):\n",
        "            sim_pos, vel, hdg = move(sim_pos, dt/step, u, wheelbase)\n",
        "            track_tmp = np.copy(sim_pos)\n",
        "            track_tmp[2] = -10\n",
        "            track.append(track_tmp)\n",
        "            velocity.append(vel)\n",
        "            heading.append(hdg)\n",
        "        track = np.array(track)\n",
        "        velocity = np.array(velocity)\n",
        "        heading = np.array(heading)\n",
        "\n",
        "        # plt.plot(track[:, 0], track[:,1], marker='.', color='k', lw=2)\n",
        "        # plt.axis('equal')\n",
        "        # plt.title(\"Robot  Trajectory\")\n",
        "        # plt.show()\n",
        "\n",
        "        mesh = trimesh.load_mesh(\"sionna_dataset_generator/models/canyon.ply\")\n",
        "\n",
        "        # create some rays\n",
        "        ray_origins = track #np.array([[0, 0, -5], [2, 2, -10]])\n",
        "        ray_directions = np.array([[0, 0, 1]]*track.shape[0])\n",
        "\n",
        "        # run the mesh- ray test\n",
        "        locations, index_ray, index_tri = mesh.ray.intersects_location(\n",
        "            ray_origins=ray_origins, ray_directions=ray_directions\n",
        "        )\n",
        "        # import pdb; pdb.set_trace()\n",
        "        if len(locations) < len(cmds) or locations.shape != (20, 3):\n",
        "            continue\n",
        "        # stack rays into line segments for visualization as Path3D\n",
        "        ray_visualize = trimesh.load_path(\n",
        "            np.hstack((ray_origins[:1], ray_origins[:1] + ray_directions[:1])).reshape(-1, 2, 3)\n",
        "        )\n",
        "        # if locations.shape != (20, 3):\n",
        "        #     import pdb; pdb.set_trace()\n",
        "\n",
        "        locations = locations[np.argsort(index_ray)]\n",
        "        locations[:, 2] += 0.5\n",
        "        locations_reshaped = locations.reshape(1, 20, 3)\n",
        "        trajectories = np.concatenate((trajectories, locations_reshaped), axis=0)\n",
        "\n",
        "        print(trajectories.shape)\n",
        "\n",
        "        # create a visualization scene with rays, hits, and mesh\n",
        "        scene = trimesh.Scene([mesh, ray_visualize, trimesh.points.PointCloud(locations)])\n",
        "\n",
        "        scene.show()\n",
        "        # # mesh.show()\n",
        "\n",
        "    np.save(\"trajectories.npy\", trajectories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55P-uX23YHYJ",
        "outputId": "43d8e731-752f-4d8a-e634-21d8a7fe8023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 20, 3)\n",
            "(2, 20, 3)\n",
            "(3, 20, 3)\n",
            "(4, 20, 3)\n",
            "(5, 20, 3)\n",
            "(6, 20, 3)\n",
            "(7, 20, 3)\n",
            "(8, 20, 3)\n",
            "(9, 20, 3)\n",
            "(10, 20, 3)\n",
            "(11, 20, 3)\n",
            "(12, 20, 3)\n",
            "(13, 20, 3)\n",
            "(14, 20, 3)\n",
            "(15, 20, 3)\n",
            "(16, 20, 3)\n",
            "(17, 20, 3)\n",
            "(18, 20, 3)\n",
            "(19, 20, 3)\n",
            "(20, 20, 3)\n",
            "(21, 20, 3)\n",
            "(22, 20, 3)\n",
            "(23, 20, 3)\n",
            "(24, 20, 3)\n",
            "(25, 20, 3)\n",
            "(26, 20, 3)\n",
            "(27, 20, 3)\n",
            "(28, 20, 3)\n",
            "(29, 20, 3)\n",
            "(30, 20, 3)\n",
            "(31, 20, 3)\n",
            "(32, 20, 3)\n",
            "(33, 20, 3)\n",
            "(34, 20, 3)\n",
            "(35, 20, 3)\n",
            "(36, 20, 3)\n",
            "(37, 20, 3)\n",
            "(38, 20, 3)\n",
            "(39, 20, 3)\n",
            "(40, 20, 3)\n",
            "(41, 20, 3)\n",
            "(42, 20, 3)\n",
            "(43, 20, 3)\n",
            "(44, 20, 3)\n",
            "(45, 20, 3)\n",
            "(46, 20, 3)\n",
            "(47, 20, 3)\n",
            "(48, 20, 3)\n",
            "(49, 20, 3)\n",
            "(50, 20, 3)\n",
            "(51, 20, 3)\n",
            "(52, 20, 3)\n",
            "(53, 20, 3)\n",
            "(54, 20, 3)\n",
            "(55, 20, 3)\n",
            "(56, 20, 3)\n",
            "(57, 20, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dataset"
      ],
      "metadata": {
        "id": "eJrj7KPxaRdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-E4Bs-W1khs",
        "outputId": "ef22751a-b9be-4c50-d1b9-088901684d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "Found 0 GPUs\n"
          ]
        }
      ],
      "source": [
        "# Jason's implementation of directional algo\n",
        "from algorithim import Params, Algorithm, Capon\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "import os\n",
        "os.environ['DRJIT_LIBLLVM_PATH'] = '/usr/lib/x86_64-linux-gnu/libLLVM.so:'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import os # Configure which GPU\n",
        "\n",
        "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
        "    gpu_num = 0 # Use \"\" to use the CPU\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
        "    print(f\"Using GPU {gpu_num}\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna\n",
        "except ImportError as e:\n",
        "    # Install Sionna if package is not already installed\n",
        "    import os\n",
        "    os.system(\"pip install sionna\")\n",
        "    import sionna\n",
        "\n",
        "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
        "# For more details, see https://www.tensorflow.org/guide/gpu\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f\"Found {len(gpus)} GPUs\")\n",
        "if gpus:\n",
        "    print(f\"Found GPU: {gpus[0].name}\")\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Avoid warnings from TensorFlow\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Colab does currently not support the latest version of ipython.\n",
        "# Thus, the preview does not work in Colab. However, whenever possible we\n",
        "# strongly recommend to use the scene preview mode.\n",
        "try: # detect if the notebook runs in Colab\n",
        "    import google.colab\n",
        "    no_preview = True # deactivate preview\n",
        "except:\n",
        "    if os.getenv(\"SIONNA_NO_PREVIEW\"):\n",
        "        no_preview = True\n",
        "    else:\n",
        "        no_preview = False\n",
        "\n",
        "resolution = [480,320] # increase for higher quality of renderings\n",
        "\n",
        "# Define magic cell command to skip a cell if needed\n",
        "from IPython.core.magic import register_cell_magic\n",
        "from IPython import get_ipython\n",
        "\n",
        "@register_cell_magic\n",
        "def skip_if(line, cell):\n",
        "    if eval(line):\n",
        "        return\n",
        "    get_ipython().run_cell(cell)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "sionna.config.seed = 42\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Import Sionna RT components\n",
        "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera, AntennaArray, Antenna\n",
        "\n",
        "# For link-level simulations\n",
        "from sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\n",
        "from sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\n",
        "from sionna.utils import compute_ber, ebnodb2no, PlotBER\n",
        "from sionna.ofdm import KBestDetector, LinearDetector\n",
        "from sionna.mimo import StreamManagement\n",
        "from sionna.ofdm import ResourceGrid\n",
        "\n",
        "def calculate_heading_rad(start, end):\n",
        "    # Calculate the difference vector\n",
        "    diff = np.array(end) - np.array(start)\n",
        "\n",
        "    # Calculate the heading angle in radians\n",
        "    heading = np.arctan2(diff[1], diff[0])\n",
        "\n",
        "    return heading\n",
        "\n",
        "def get_rss_from_csi(csi):\n",
        "  # Compute CSI power (power per subcarrier)\n",
        "  csi_power = tf.abs(csi)**2\n",
        "\n",
        "  # Compute RSS per receiver-transmitter pair (sum over subcarriers)\n",
        "  rss_per_rx_tx = tf.reduce_sum(csi_power, axis=-1)  # Sum over subcarriers\n",
        "\n",
        "  # Convert RSS from linear scale (e.g., Watts) to dBm\n",
        "  rss_per_rx_tx_dBm = 10 * tf.math.log(rss_per_rx_tx / 1e-3) / tf.math.log(10.0)\n",
        "\n",
        "  return rss_per_rx_tx_dBm\n",
        "\n",
        "def dbm_to_watts(dbm):\n",
        "    return 10. ** ((dbm-30)/10)\n",
        "\n",
        "def watts_to_dbm(watts):\n",
        "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
        "    return 10 * np.log10(watts + epsilon) + 30\n",
        "\n",
        "# # Multiple Antennas like ASUS Router\n",
        "def get_antenna_positions(spacing):\n",
        "    return np.array([[0.0, spacing / 2 + spacing , 0.0],\n",
        "                     [0.0, spacing / 2, 0.0],\n",
        "                     [0.0, -spacing / 2, 0.0],\n",
        "                     [0.0, -spacing / 2 - spacing, 0.0]])\n",
        "\n",
        "def flip_trajectory(data):\n",
        "    # Vector from origin to the first and last points of each trajectory\n",
        "    first_points = data[:, 0, :]  # Shape (1000, 3)\n",
        "    last_points = data[:, -1, :]  # Shape (1000, 3)\n",
        "\n",
        "    # Compute the dot product of the first and last points with respect to the origin\n",
        "    dot_products = np.sum(first_points * last_points, axis=1)\n",
        "\n",
        "    # Identify trajectories heading away from the origin (dot product > 0)\n",
        "    away_from_origin = dot_products < 0\n",
        "\n",
        "    # Flip the trajectories that are not heading away from the origin\n",
        "    data[~away_from_origin] = data[~away_from_origin, ::-1, :]\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "yRjrqzAk3AtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List for dataset\n",
        "angles = []\n",
        "angle_profile_values = []\n",
        "rssi = []\n",
        "rssi_normalized = []\n",
        "data = []\n",
        "total_traj = 20 # len(trajectories)\n",
        "\n",
        "for traj in range(total_traj):\n",
        "    SCENE_NAME = \"canyon\"\n",
        "    IMAGE_FOLDER = f\"images/{SCENE_NAME}\"\n",
        "\n",
        "    # Load integrated scene\n",
        "    scene = load_scene(f\"sionna_dataset_generator/models/{SCENE_NAME}.xml\") # Try also sionna.rt.scene.etoile\n",
        "\n",
        "    # Configure antenna array for all transmitters\n",
        "    scene.tx_array = PlanarArray(num_rows=1,\n",
        "                                num_cols=1,\n",
        "                                vertical_spacing=0.5,\n",
        "                                horizontal_spacing=0.5,\n",
        "                                pattern=\"iso\",\n",
        "                                polarization=\"V\")\n",
        "\n",
        "    antenna_positions = get_antenna_positions(0.03)\n",
        "    antenna_array_angle = -175 # Default\n",
        "\n",
        "    RelativeAntennas = AntennaArray(antenna=Antenna(\"dipole\", \"V\"),\n",
        "                                positions=tf.Variable(antenna_positions.tolist()))\n",
        "\n",
        "    # scene.tx_array = RelativeAntennas\n",
        "    scene.rx_array = RelativeAntennas\n",
        "\n",
        "    # Create transmitter\n",
        "    tx = Transmitter(name=\"tx\",\n",
        "                    position=[0., -10., 0.],\n",
        "                    orientation=[np.radians(0),0,0])\n",
        "\n",
        "    # Add transmitter instance to scene\n",
        "    scene.add(tx)\n",
        "\n",
        "    trajectories = np.load('sionna_dataset_generator/trajectories_2.npy')\n",
        "    trajectories = flip_trajectory(trajectories)\n",
        "    trajectory_index = traj\n",
        "    num_steps = trajectories.shape[1]\n",
        "    trajectory_steps =  np.arange(num_steps - 1)\n",
        "\n",
        "    start_color = np.array([1, 0, 0])  # Red\n",
        "    end_color = np.array([0, 0, 1])\n",
        "    colors = [start_color + (end_color - start_color) * i / (num_steps - 1) for i in range(num_steps)]\n",
        "\n",
        "    # Calculate headings for the trajectory\n",
        "    calculated_headings = []\n",
        "    for i in trajectory_steps: #range(0, len(trajectories[0]) - 1):\n",
        "        heading = calculate_heading_rad(trajectories[trajectory_index,i,:2], trajectories[trajectory_index,i + 1,:2])\n",
        "        calculated_headings.append(heading)\n",
        "\n",
        "    rxs = []\n",
        "    for i, position in enumerate(trajectories[trajectory_index, np.arange(num_steps) ,:]):\n",
        "        if i == (trajectories[0].shape[0] - 1):\n",
        "            heading = calculated_headings[-1]\n",
        "        else:\n",
        "            heading = calculated_headings[i]\n",
        "        rxs.append(Receiver(name=f\"rx{i}\",\n",
        "                position=position,\n",
        "                orientation=[heading,0,0]))\n",
        "        scene.add(rxs[i])\n",
        "\n",
        "    antenna_array_angle = np.radians(180) # heading\n",
        "\n",
        "    scene.frequency = 2.14e9 #5.745 # in Hz; implicitly updates RadioMaterials\n",
        "\n",
        "    scene.synthetic_array = False # If set to False, ray tracing will be done per antenna element (slower for large arrays)\n",
        "\n",
        "    # Compute propagation paths\n",
        "    paths = scene.compute_paths(max_depth=5,\n",
        "                                num_samples=1e6,  # Number of rays shot into directions defined\n",
        "                                                # by a Fibonacci sphere , too few rays can\n",
        "                                                # lead to missing paths\n",
        "                                los=True,  # Include Line-of-Sight paths\n",
        "                                reflection=True,  # Include reflection paths\n",
        "                                diffraction=True,  # Include diffraction paths\n",
        "                                scattering=True,  # Include scattering paths\n",
        "                                )\n",
        "\n",
        "    paths.normalize_delays = False\n",
        "\n",
        "    # Determine subcarrier frequencies\n",
        "    rg = ResourceGrid(num_ofdm_symbols=1,\n",
        "                    fft_size=52,\n",
        "                    dc_null = True,\n",
        "                    cyclic_prefix_length=20,\n",
        "                    #   pilot_pattern = \"kronecker\",\n",
        "                    #   pilot_ofdm_symbol_indices = [2, 8],\n",
        "                    subcarrier_spacing=5e6) #30e3)\n",
        "\n",
        "    frequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n",
        "\n",
        "    # get rss\n",
        "    a, tau = paths.cir()\n",
        "\n",
        "    csi = cir_to_ofdm_channel(frequencies, a, tau, normalize=False)  # Non-normalized includes path-loss\n",
        "\n",
        "    csi_reshaped = []\n",
        "    for i in range(len(rxs)):\n",
        "        csi_reshaped.append(np.array(csi[:,i,:,:,:,:,:]).reshape(4, 52))\n",
        "\n",
        "    #Output: h_f ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, fft_size], tf.complex) – Channel frequency responses at frequencies\n",
        "    block_rss = get_rss_from_csi(csi).numpy()[0, :, 0, 0, 0, 0]\n",
        "    block_rss[np.isneginf(block_rss)] = -90\n",
        "    rssi.append(block_rss[:-1])\n",
        "    # Define range\n",
        "    min_rss = -90\n",
        "    max_rss = 0\n",
        "\n",
        "    # Normalize values to 0-1\n",
        "    normalized = (block_rss - min_rss) / (max_rss - min_rss)\n",
        "    rssi_normalized.append(normalized[:-1])\n",
        "\n",
        "    # Define three colors\n",
        "    color_black = np.array([0, 0, 0])\n",
        "    color_red = np.array([1, 0, 0])\n",
        "    color_blue = np.array([0, 0, 1])\n",
        "    colors = []\n",
        "    for value in normalized:\n",
        "        if value <= 0.5:\n",
        "            # Scale between black and gray\n",
        "            color = color_black + (color_red - color_black) * (value / 0.5)\n",
        "        else:\n",
        "            # Scale between gray and white\n",
        "            color = color_red + (color_blue - color_red) * ((value - 0.5) / 0.5)\n",
        "        colors.append(color)\n",
        "\n",
        "    # Map normalized values to colors\n",
        "    # 0-1 range is split into 3 intervals: [0, 1/3), [1/3, 2/3), [2/3, 1]\n",
        "    # color_indices = np.digitize(normalized, bins=[1/3, 2/3], right=False)\n",
        "    # mapped_colors = [colors[idx] for idx in color_indices]\n",
        "\n",
        "    for i, rx in enumerate(rxs):\n",
        "        rx.color = colors[i]\n",
        "\n",
        "\n",
        "    # Implementing Capon Algorithim\n",
        "    params = Params(antenna_positions[:, :2])\n",
        "\n",
        "    angle_tmp = []\n",
        "    angle_profile_values_tmp = []\n",
        "    for i in range(0, len(rxs) - 1):\n",
        "\n",
        "        csi_tmp = tf.reshape(csi[:,i,:,:,:,:,:], [4, 52]) #  tf.reshape(csi[:,i,:,:,:,:,:], [1, -1])\n",
        "\n",
        "        AOA, theta_samples, profile_norm = Capon(params, 155, 80, csi_tmp).evaluate()\n",
        "\n",
        "        # This for when going towards transmitter\n",
        "        profile_norm = np.roll(profile_norm, 180)\n",
        "        # Capture three top peaks from bottom of profile (90-270 degrees)\n",
        "        evaluation = np.array([profile_norm[90:270]])\n",
        "        evaluation = evaluation.flatten()\n",
        "        peaks, _ = find_peaks(evaluation)\n",
        "        peak_values = evaluation[peaks]\n",
        "        angle_profile_values_tmp.append(np.pad(peak_values, (0, max(0, 3 - peak_values.shape[0])), mode='constant'))\n",
        "        angle_tmp.append(np.pad(theta_samples[90:270][peaks], (0, max(0, 3 - theta_samples[90:270][peaks].shape[0])), mode='constant'))\n",
        "        AOA = np.array([AOA])\n",
        "\n",
        "\n",
        "    angles.append(angle_tmp)\n",
        "    angle_profile_values.append(angle_profile_values_tmp)\n",
        "\n",
        "for i in range(0, len(rssi)):\n",
        "  prev_angles = []\n",
        "  prev_angle_profiles = []\n",
        "  prev_rssi = []\n",
        "  for j in range(0, len(rssi[i]) - 1):\n",
        "    prev_angles.append([angles[i][j][0], angles[i][j][1], angles[i][j][2]])\n",
        "    prev_angle_profiles.append([angle_profile_values[i][j][0], angle_profile_values[i][j][1], angle_profile_values[i][j][2]])\n",
        "    prev_rssi.append(rssi_normalized[i][j])\n",
        "  data.append([rssi_normalized[i][len(rssi[i]) - 1], prev_angles, prev_angle_profiles, prev_rssi])"
      ],
      "metadata": {
        "id": "7idckk-F3Eqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)\n",
        "print(len(data))\n",
        "print(len(data[0][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TMBVoHI-4USq",
        "outputId": "a167c8f1-c31d-402c-91c1-e5ec0db14695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec68a76c29ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(rssi))\n",
        "print(len(rssi[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfoK2dVHgOQZ",
        "outputId": "9a31aaa1-feda-43c0-f4f9-b2cb36f7852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def list_to_csv(data_list, filename):\n",
        "    \"\"\"\n",
        "    Writes a list of lists to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        data_list (list of lists): The data to write to the CSV file.\n",
        "        filename (str): The name of the CSV file to create.\n",
        "    \"\"\"\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerows(data_list)\n",
        "\n",
        "list_to_csv(data, 'dataset.csv')"
      ],
      "metadata": {
        "id": "FQ9uYWWb5XBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}